{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-02-tokenizer-과제.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6dfJPT-2XMTB",
        "JHkHg6XAXoyK",
        "sEbpKyPxz6qs",
        "b7GZHAJc8R1W",
        "_8ajMz_ZCCxs",
        "zeBCtb61bG8Y"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dfJPT-2XMTB"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a193aGJWVaqb",
        "outputId": "74c654f8-4b2f-49ca-889a-b5ae9d63fb8c"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHkHg6XAXoyK"
      },
      "source": [
        "# Evn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkYXFwcBXJDG"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import json\n",
        "import zipfile\n",
        "import math\n",
        "import copy\n",
        "import collections\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sentencepiece as spm\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvjyruUlXtlR"
      },
      "source": [
        "# random seed initialize\n",
        "random_seed = 1234\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC3fXkhdYcYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a143a80-c598-4279-8d4a-410d9cbfd71e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jan 26 13:21:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVRdxYReYeQj",
        "outputId": "0b28e6ce-068b-461a-b58f-0f37a1caacac"
      },
      "source": [
        "# google drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byCIiLJBbFHh",
        "outputId": "7f57168e-19fe-4a97-9d5a-890e1d32d95f"
      },
      "source": [
        "# data dir\n",
        "data_dir = '/content/drive/MyDrive'\n",
        "os.listdir(data_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Colab Notebooks',\n",
              " '01-02-simple-project-과제.ipynb',\n",
              " 'ko_32000.model',\n",
              " 'ko_32000.vocab',\n",
              " '02-01-encoding-강의.ipynb',\n",
              " '.ipynb_checkpoints',\n",
              " 'kowiki',\n",
              " '02-02-tokenizer-강의.ipynb',\n",
              " '02-02-tokenizer-과제.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H0BLydCb7lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5669806a-8fd8-43cf-9d2c-bae4bdaa4363"
      },
      "source": [
        "# kowiki dir\n",
        "kowiki_dir = os.path.join(data_dir, 'kowiki')\n",
        "if not os.path.exists(kowiki_dir):\n",
        "    os.makedirs(kowiki_dir)\n",
        "os.listdir(kowiki_dir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kowiki.txt.zip', 'my_corpus.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEbpKyPxz6qs"
      },
      "source": [
        "# Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3xx7dJYz9jt"
      },
      "source": [
        "text = \"\"\"위키백과의 최상위 도메인이 .com이던 시절 ko.wikipedia.com에 구판 미디어위키가 깔렸으나 한글 처리에 문제가 있어 글을 올릴 수도 없는 이름뿐인 곳이었다. 2002년 10월에 새로운 위키 소프트웨어를 쓰면서 한글 처리 문제가 풀리기 시작했지만, 가장 많은 사람이 쓰는 인터넷 익스플로러에서는 인코딩 문제가 여전했다. 이런 이유로 초기에는 도움말을 옮기거나 쓰는 일에 어려움을 겪었다. 이런 어려움이 있었는데도 위키백과 통계로는, 2002년 10월에서 2003년 7월까지 열 달 사이에 글이 13개에서 159개로 늘었고 2003년 7월과 8월 사이에는 한 달 만에 159개에서 348개로 늘어났다. 2003년 9월부터는 인터넷 익스플로러의 인코딩 문제가 사라졌으며, 대한민국 언론에서도 몇 차례 위키백과를 소개하면서 참여자가 점증하리라고 예측했다. 참고로 한국어 위키백과의 최초 문서는 2002년 10월 12일에 등재된 지미 카터 문서이다.\n",
        "2005년 6월 5일 양자장론 문서 등재를 기점으로 총 등재 문서 수가 1만 개를 돌파하였고 이어 동해 11월에 제1회 정보트러스트 어워드 인터넷 문화 일반 분야에 선정되었다. 2007년 8월 9일에는 한겨레21에서 한국어 위키백과와 위키백과 오프라인 첫 모임을 취재한 기사를 표지 이야기로 다루었다.\n",
        "2008년 광우병 촛불 시위 때 생긴 신조어인 명박산성이 한국어 위키백과에 등재되고 이 문서의 존치 여부를 두고 갑론을박의 과정이 화제가 되고 각종 매체에도 보도가 되었다. 시위대의 난입과 충돌을 방지하기 위해 거리에 설치되었던 컨테이너 박스를 이명박 정부의 불통으로 풍자를 하기 위해 사용된 이 신조어는 중립성을 지켰는지와 백과사전에 올라올 만한 문서인지가 쟁점이 되었는데 일시적으로 사용된 신조어일 뿐이라는 주장과 이미 여러 매체에서 사용되어 지속성이 보장되었다는 주장 등 논쟁이 벌어졌고 다음 아고라 등지에서 이 항목을 존치하는 방안을 지지하는 의견을 남기기 위해 여러 사람이 새로 가입하는 등 혼란이 빚어졌다. 11월 4일에는 다음커뮤니케이션에서 글로벌 세계 대백과사전을 기증받았으며, 2009년 3월에는 서울특별시로부터 콘텐츠를 기증받았다. 2009년 6월 4일에는 액세스권 등재를 기점으로 10만 개 문서 수를 돌파했다.\n",
        "2011년 4월 16일에는 대한민국에서의 위키미디어 프로젝트를 지원하는 모임을 결성할 것을 추진하는 논의가 이뤄졌고 이후 창립준비위원회 결성을 거쳐 2014년 10월 19일 창립총회를 개최하였으며, 최종적으로 2015년 11월 4일 사단법인 한국 위키미디어 협회가 결성되어 활동 중에 있다. 2019년 미국 위키미디어재단으로부터 한국 지역 지부(챕터)로 승인을 받았다.\n",
        "2012년 5월 19일에는 보비 탬블링 등재를 기점으로 총 20만 개 문서가 등재되었고 2015년 1월 5일, Rojo -Tierra- 문서 등재를 기점으로 총 30만 개 문서가 등재되었다. 2017년 10월 21일에는 충청남도 동물위생시험소 문서 등재로 40만 개의 문서까지 등재되었다.\"\"\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7GZHAJc8R1W"
      },
      "source": [
        "# Google sentencepiece를 이용해 vocab 생성\n",
        "- https://github.com/google/sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8ajMz_ZCCxs"
      },
      "source": [
        "## sentencepe 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQKAKbPN6miL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4036af2-f058-40db-a253-d09f5be32d2b"
      },
      "source": [
        "os.listdir(kowiki_dir)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kowiki.txt.zip', 'my_corpus.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d99Y3Fkdvftw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6db2945-eb1f-4142-a839-5d1e11851c63"
      },
      "source": [
        "shutil.copy(os.path.join(kowiki_dir, 'my_corpus.txt'), './')\n",
        "os.listdir('./')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'drive', 'my_corpus.txt', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwDPlGeeCF70"
      },
      "source": [
        "def train_sentencepiece(corpus, prefix, vocab_size=32000):\n",
        "    \"\"\"\n",
        "    sentencepiece를 이용해 vocab 학습\n",
        "    :param corpus: 학습할 말뭉치\n",
        "    :param prefix: 저장할 vocab 이름\n",
        "    :param vocab_size: vocab 개수\n",
        "    \"\"\"\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" +  # 7은 특수문자 개수\n",
        "        \" --model_type=unigram\" +\n",
        "        \" --max_sentence_length=999999\" +  # 문장 최대 길이\n",
        "        \" --pad_id=0 --pad_piece=[PAD]\" +  # pad token 및 id 지정\n",
        "        \" --unk_id=1 --unk_piece=[UNK]\" +  # unknown token 및 id 지정\n",
        "        \" --bos_id=2 --bos_piece=[BOS]\" +  # begin of sequence token 및 id 지정\n",
        "        \" --eos_id=3 --eos_piece=[EOS]\" +  # end of sequence token 및 id 지정\n",
        "        \" --user_defined_symbols=[SEP],[CLS],[MASK]\")  # 기타 추가 토큰 SEP: 4, CLS: 5, MASK: 6"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE-yJ_cSCYz0"
      },
      "source": [
        "# vocab 생성\n",
        "train_sentencepiece(f\"my_corpus.txt\", f\"my_vocab\", vocab_size=425)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85eoYIgZNtYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddaacdfe-de8d-4839-ce96-fa673fcb822d"
      },
      "source": [
        "os.listdir(\".\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'my_vocab.vocab',\n",
              " 'my_vocab.model',\n",
              " 'drive',\n",
              " 'my_corpus.txt',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeBCtb61bG8Y"
      },
      "source": [
        "## sentencepe 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySjtyzUGbLwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b16a80-783d-4002-ce13-c6b73afa0052"
      },
      "source": [
        "# load vocab\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(f\"my_vocab.model\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJrlfRqObeEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fab2d23-7a38-48db-dabc-5cbf01091bba"
      },
      "source": [
        "# vocab 출력\n",
        "print(f\"len: {len(vocab)}\")\n",
        "for id in range(16):\n",
        "    print(f\"{id:2d}: {vocab.id_to_piece(id)}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len: 432\n",
            " 0: [PAD]\n",
            " 1: [UNK]\n",
            " 2: [BOS]\n",
            " 3: [EOS]\n",
            " 4: [SEP]\n",
            " 5: [CLS]\n",
            " 6: [MASK]\n",
            " 7: ▁\n",
            " 8: 는\n",
            " 9: .\n",
            "10: 을\n",
            "11: 고\n",
            "12: 이\n",
            "13: 에\n",
            "14: 다\n",
            "15: \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWlGnwd9bh67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542f4ea6-051a-4778-900d-a4c2a76f1910"
      },
      "source": [
        "# text를 tokenize 함\n",
        "# sentence to pieces\n",
        "pieces = vocab.encode_as_pieces(text)\n",
        "print(pieces[0:100])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁', '위', '키', '백', '과', '의', '▁최', '상', '위', '▁', '도', '메', '인', '이', '▁', '.', 'c', 'o', 'm', '이', '던', '▁시', '절', '▁', 'k', 'o', '.', 'wi', 'k', 'ip', 'e', 'di', 'a', '.', 'c', 'o', 'm', '에', '▁', '구판', '▁', '미디', '어', '위', '키', '가', '▁', '깔렸', '으', '나', '▁한', '글', '▁', '처', '리', '에', '▁', '문', '제', '가', '▁있', '어', '▁', '글', '을', '▁', '올', '릴', '▁수', '도', '▁', '없', '는', '▁이', '름뿐', '인', '▁', '곳', '이', '었', '다', '.', '▁2', '0', '0', '2', '년', '▁1', '0', '월', '에', '▁', '새', '로', '운', '▁', '위', '키', '▁', '소']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1lUjSWh_MRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78ce022-6c70-4fee-9b40-0de69e9f0cdd"
      },
      "source": [
        "vocab.encode_as_pieces(\"나는 오늘 수원에 놀러 갔다.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁',\n",
              " '나',\n",
              " '는',\n",
              " '▁',\n",
              " '오',\n",
              " '늘',\n",
              " '▁수',\n",
              " '원',\n",
              " '에',\n",
              " '▁',\n",
              " '놀',\n",
              " '러',\n",
              " '▁',\n",
              " '갔',\n",
              " '다',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aaBGd8R_Ue3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802e869b-c71e-4143-a41b-735efb6b7cec"
      },
      "source": [
        "vocab.encode_as_pieces(\"나는 오늘 배가많이고파서밥을많이먹은후 놀러 갔다.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁',\n",
              " '나',\n",
              " '는',\n",
              " '▁',\n",
              " '오',\n",
              " '늘',\n",
              " '▁',\n",
              " '배',\n",
              " '가',\n",
              " '많',\n",
              " '이',\n",
              " '고',\n",
              " '파',\n",
              " '서',\n",
              " '밥',\n",
              " '을',\n",
              " '많',\n",
              " '이',\n",
              " '먹',\n",
              " '은',\n",
              " '후',\n",
              " '▁',\n",
              " '놀',\n",
              " '러',\n",
              " '▁',\n",
              " '갔',\n",
              " '다',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2PsfHS7bt6j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "1f9b26f8-596a-4165-913d-109282e57b72"
      },
      "source": [
        "# tokenize된 값을 string 으로 복원\n",
        "# pieces to sentence\n",
        "vocab.decode_pieces(pieces)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'위키백과의 최상위 도메인이 .com이던 시절 ko.wikipedia.com에 구판 미디어위키가 깔렸으나 한글 처리에 문제가 있어 글을 올릴 수도 없는 이름뿐인 곳이었다. 2002년 10월에 새로운 위키 소프트웨어를 쓰면서 한글 처리 문제가 풀리기 시작했지만, 가장 많은 사람이 쓰는 인터넷 익스플로러에서는 인코딩 문제가 여전했다. 이런 이유로 초기에는 도움말을 옮기거나 쓰는 일에 어려움을 겪었다. 이런 어려움이 있었는데도 위키백과 통계로는, 2002년 10월에서 2003년 7월까지 열 달 사이에 글이 13개에서 159개로 늘었고 2003년 7월과 8월 사이에는 한 달 만에 159개에서 348개로 늘어났다. 2003년 9월부터는 인터넷 익스플로러의 인코딩 문제가 사라졌으며, 대한민국 언론에서도 몇 차례 위키백과를 소개하면서 참여자가 점증하리라고 예측했다. 참고로 한국어 위키백과의 최초 문서는 2002년 10월 12일에 등재된 지미 카터 문서이다. 2005년 6월 5일 양자장론 문서 등재를 기점으로 총 등재 문서 수가 1만 개를 돌파하였고 이어 동해 11월에 제1회 정보트러스트 어워드 인터넷 문화 일반 분야에 선정되었다. 2007년 8월 9일에는 한겨레21에서 한국어 위키백과와 위키백과 오프라인 첫 모임을 취재한 기사를 표지 이야기로 다루었다. 2008년 광우병 촛불 시위 때 생긴 신조어인 명박산성이 한국어 위키백과에 등재되고 이 문서의 존치 여부를 두고 갑론을박의 과정이 화제가 되고 각종 매체에도 보도가 되었다. 시위대의 난입과 충돌을 방지하기 위해 거리에 설치되었던 컨테이너 박스를 이명박 정부의 불통으로 풍자를 하기 위해 사용된 이 신조어는 중립성을 지켰는지와 백과사전에 올라올 만한 문서인지가 쟁점이 되었는데 일시적으로 사용된 신조어일 뿐이라는 주장과 이미 여러 매체에서 사용되어 지속성이 보장되었다는 주장 등 논쟁이 벌어졌고 다음 아고라 등지에서 이 항목을 존치하는 방안을 지지하는 의견을 남기기 위해 여러 사람이 새로 가입하는 등 혼란이 빚어졌다. 11월 4일에는 다음커뮤니케이션에서 글로벌 세계 대백과사전을 기증받았으며, 2009년 3월에는 서울특별시로부터 콘텐츠를 기증받았다. 2009년 6월 4일에는 액세스권 등재를 기점으로 10만 개 문서 수를 돌파했다. 2011년 4월 16일에는 대한민국에서의 위키미디어 프로젝트를 지원하는 모임을 결성할 것을 추진하는 논의가 이뤄졌고 이후 창립준비위원회 결성을 거쳐 2014년 10월 19일 창립총회를 개최하였으며, 최종적으로 2015년 11월 4일 사단법인 한국 위키미디어 협회가 결성되어 활동 중에 있다. 2019년 미국 위키미디어재단으로부터 한국 지역 지부(챕터)로 승인을 받았다. 2012년 5월 19일에는 보비 탬블링 등재를 기점으로 총 20만 개 문서가 등재되었고 2015년 1월 5일, Rojo -Tierra- 문서 등재를 기점으로 총 30만 개 문서가 등재되었다. 2017년 10월 21일에는 충청남도 동물위생시험소 문서 등재로 40만 개의 문서까지 등재되었다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2NoPR4Tb5GB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed741e4f-460d-4609-a749-30b2caa132c6"
      },
      "source": [
        "# tokenize된 값을 id로 변경\n",
        "# piece to id\n",
        "piece_ids = []\n",
        "for piece in pieces:\n",
        "    piece_ids.append(vocab.piece_to_id(piece))\n",
        "piece_ids[0:100]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7,\n",
              " 171,\n",
              " 1,\n",
              " 400,\n",
              " 63,\n",
              " 48,\n",
              " 236,\n",
              " 65,\n",
              " 171,\n",
              " 7,\n",
              " 58,\n",
              " 1,\n",
              " 35,\n",
              " 12,\n",
              " 7,\n",
              " 9,\n",
              " 370,\n",
              " 373,\n",
              " 1,\n",
              " 12,\n",
              " 190,\n",
              " 72,\n",
              " 1,\n",
              " 7,\n",
              " 213,\n",
              " 373,\n",
              " 9,\n",
              " 1,\n",
              " 213,\n",
              " 1,\n",
              " 371,\n",
              " 1,\n",
              " 215,\n",
              " 9,\n",
              " 370,\n",
              " 373,\n",
              " 1,\n",
              " 13,\n",
              " 7,\n",
              " 1,\n",
              " 7,\n",
              " 1,\n",
              " 66,\n",
              " 171,\n",
              " 1,\n",
              " 18,\n",
              " 7,\n",
              " 1,\n",
              " 50,\n",
              " 26,\n",
              " 158,\n",
              " 1,\n",
              " 7,\n",
              " 426,\n",
              " 170,\n",
              " 13,\n",
              " 7,\n",
              " 401,\n",
              " 86,\n",
              " 18,\n",
              " 160,\n",
              " 66,\n",
              " 7,\n",
              " 1,\n",
              " 10,\n",
              " 7,\n",
              " 1,\n",
              " 305,\n",
              " 54,\n",
              " 58,\n",
              " 7,\n",
              " 1,\n",
              " 8,\n",
              " 42,\n",
              " 1,\n",
              " 35,\n",
              " 7,\n",
              " 1,\n",
              " 12,\n",
              " 1,\n",
              " 14,\n",
              " 9,\n",
              " 140,\n",
              " 128,\n",
              " 128,\n",
              " 251,\n",
              " 1,\n",
              " 101,\n",
              " 128,\n",
              " 1,\n",
              " 13,\n",
              " 7,\n",
              " 1,\n",
              " 20,\n",
              " 1,\n",
              " 7,\n",
              " 171,\n",
              " 1,\n",
              " 7,\n",
              " 317]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6PGUrK9cHxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662c68b4-3f0d-44b9-d1af-8c8aeb4893fa"
      },
      "source": [
        "# text를 id로 tokenize 함\n",
        "# sentence to ids\n",
        "ids = vocab.encode_as_ids(text)\n",
        "print(ids)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 171, 1, 400, 63, 48, 236, 65, 171, 7, 58, 1, 35, 12, 7, 9, 370, 373, 1, 12, 190, 72, 1, 7, 213, 373, 9, 1, 213, 1, 371, 1, 215, 9, 370, 373, 1, 13, 7, 1, 7, 1, 66, 171, 1, 18, 7, 1, 50, 26, 158, 1, 7, 426, 170, 13, 7, 401, 86, 18, 160, 66, 7, 1, 10, 7, 1, 305, 54, 58, 7, 1, 8, 42, 1, 35, 7, 1, 12, 1, 14, 9, 140, 128, 128, 251, 1, 101, 128, 1, 13, 7, 1, 20, 1, 7, 171, 1, 7, 317, 1, 66, 23, 7, 1, 21, 17, 158, 1, 7, 426, 170, 7, 401, 86, 18, 7, 1, 170, 244, 72, 123, 425, 228, 27, 7, 18, 260, 7, 365, 29, 142, 1, 12, 7, 1, 8, 7, 35, 67, 1, 7, 1, 200, 1, 20, 119, 44, 8, 7, 35, 88, 1, 7, 401, 86, 18, 7, 122, 157, 24, 9, 42, 1, 42, 397, 20, 7, 1, 244, 13, 8, 7, 58, 1, 412, 10, 7, 1, 244, 428, 26, 7, 1, 8, 7, 47, 13, 7, 66, 106, 1, 10, 7, 287, 1, 14, 9, 42, 1, 7, 66, 106, 1, 12, 160, 1, 8, 298, 58, 7, 171, 1, 400, 63, 7, 349, 75, 20, 8, 27, 140, 128, 128, 251, 1, 101, 128, 1, 44, 140, 128, 128, 211, 1, 7, 175, 1, 293, 22, 181, 7, 165, 142, 12, 13, 7, 1, 12, 101, 211, 147, 44, 101, 255, 79, 147, 20, 7, 1, 11, 140, 128, 128, 211, 1, 7, 175, 1, 63, 7, 281, 1, 142, 12, 13, 8, 158, 7, 165, 7, 162, 13, 101, 255, 79, 147, 44, 7, 211, 280, 281, 147, 20, 7, 1, 66, 295, 14, 9, 140, 128, 128, 211, 1, 7, 79, 1, 57, 67, 8, 7, 35, 67, 1, 7, 1, 200, 1, 20, 119, 48, 7, 35, 88, 1, 7, 401, 86, 18, 142, 102, 1, 50, 307, 27, 144, 30, 309, 1, 7, 1, 44, 58, 7, 1, 235, 304, 7, 171, 1, 400, 63, 23, 7, 317, 147, 41, 21, 17, 7, 334, 122, 76, 18, 7, 1, 411, 41, 170, 102, 11, 234, 1, 24, 9, 7, 334, 11, 20, 158, 1, 66, 7, 171, 1, 400, 63, 48, 236, 1, 7, 401, 17, 8, 140, 128, 128, 251, 1, 101, 128, 1, 101, 251, 47, 13, 34, 423, 64, 39, 1, 7, 341, 67, 7, 401, 17, 12, 14, 9, 140, 128, 128, 255, 1, 7, 409, 1, 94, 47, 7, 322, 76, 260, 1, 7, 401, 17, 34, 423, 23, 141, 1, 50, 20, 7, 338, 34, 423, 7, 401, 17, 54, 18, 101, 162, 381, 23, 7, 1, 279, 41, 1, 11, 42, 66, 7, 404, 33, 101, 38, 1, 13, 7, 86, 38, 161, 382, 389, 1, 119, 200, 1, 7, 66, 1, 300, 7, 35, 67, 1, 7, 401, 126, 7, 47, 164, 7, 314, 121, 13, 7, 316, 146, 74, 1, 14, 9, 140, 128, 128, 175, 1, 7, 281, 1, 7, 79, 47, 13, 8, 158, 1, 251, 38, 44, 158, 1, 66, 7, 171, 1, 400, 63, 201, 7, 171, 1, 400, 63, 7, 323, 1, 102, 35, 7, 1, 59, 10, 7, 1, 423, 30, 141, 153, 23, 7, 103, 22, 42, 121, 244, 20, 7, 14, 1, 14, 9, 140, 128, 128, 281, 1, 7, 290, 278, 1, 7, 1, 72, 171, 7, 193, 7, 78, 1, 7, 319, 431, 66, 35, 7, 209, 1, 315, 199, 12, 158, 1, 66, 7, 171, 1, 400, 63, 13, 34, 423, 74, 11, 42, 7, 401, 17, 48, 7, 331, 172, 7, 122, 57, 23, 231, 11, 7, 1, 10, 1, 48, 7, 63, 146, 12, 7, 126, 86, 18, 7, 74, 11, 7, 83, 167, 7, 1, 246, 13, 58, 208, 58, 18, 7, 74, 1, 14, 9, 72, 171, 154, 48, 7, 187, 1, 63, 7, 339, 1, 10, 143, 22, 41, 244, 7, 171, 33, 361, 170, 13, 45, 172, 74, 1, 190, 7, 1, 348, 12, 1, 7, 1, 200, 23, 42, 209, 1, 37, 48, 7, 1, 349, 50, 20, 7, 1, 76, 23, 7, 41, 244, 7, 171, 33, 142, 325, 64, 42, 7, 319, 431, 66, 8, 53, 1, 199, 10, 39, 1, 8, 22, 201, 108, 63, 153, 157, 13, 7, 1, 102, 1, 7, 162, 30, 7, 401, 17, 35, 22, 18, 7, 1, 12, 7, 74, 1, 8, 298, 7, 47, 152, 36, 50, 20, 142, 325, 64, 7, 319, 431, 66, 47, 7, 1, 52, 8, 242, 260, 63, 42, 1, 7, 122, 119, 7, 1, 246, 44, 142, 325, 74, 66, 39, 1, 199, 12, 208, 260, 74, 1, 14, 8, 242, 260, 34, 7, 419, 1, 12, 7, 1, 66, 1, 11, 7, 14, 327, 239, 11, 102, 34, 22, 44, 42, 7, 1, 390, 10, 7, 331, 172, 41, 8, 143, 77, 10, 39, 22, 41, 8, 61, 10, 7, 1, 244, 244, 7, 171, 33, 7, 122, 119, 142, 1, 12, 7, 1, 20, 7, 18, 1, 41, 8, 34, 7, 1, 12, 7, 1, 66, 1, 14, 9, 101, 38, 1, 7, 280, 47, 13, 8, 7, 14, 327, 1, 405, 1, 12, 1, 44, 7, 1, 20, 1, 7, 1, 75, 144, 400, 63, 153, 157, 10, 141, 411, 311, 212, 50, 307, 27, 140, 128, 128, 79, 1, 7, 211, 1, 13, 8, 7, 131, 396, 265, 152, 20, 57, 67, 7, 1, 23, 141, 411, 311, 212, 14, 9, 140, 128, 128, 79, 1, 7, 409, 1, 7, 280, 47, 13, 8, 7, 1, 200, 130, 34, 423, 23, 141, 1, 50, 20, 101, 128, 162, 381, 7, 401, 17, 54, 23, 7, 1, 279, 24, 9, 140, 128, 38, 38, 1, 7, 280, 1, 101, 409, 47, 13, 8, 144, 30, 309, 1, 44, 48, 7, 171, 1, 66, 7, 1, 20, 1, 23, 39, 202, 41, 8, 59, 10, 7, 407, 199, 32, 28, 10, 185, 107, 41, 8, 43, 18, 42, 1, 11, 42, 90, 7, 1, 332, 415, 171, 202, 161, 7, 407, 199, 10, 361, 337, 140, 128, 38, 280, 1, 101, 128, 1, 101, 79, 47, 7, 1, 338, 161, 23, 381, 254, 41, 1, 50, 307, 27, 236, 167, 36, 50, 20, 140, 128, 38, 255, 1, 101, 38, 1, 7, 280, 47, 142, 163, 1, 35, 158, 1, 7, 171, 1, 66, 7, 355, 161, 18, 7, 407, 199, 74, 66, 7, 274, 404, 53, 13, 31, 9, 140, 128, 38, 79, 1, 7, 1, 7, 171, 1, 66, 423, 163, 50, 20, 57, 67, 158, 1, 39, 245, 39, 57, 248, 1, 67, 19, 20, 7, 318, 35, 10, 7, 311, 212, 14, 9, 140, 128, 38, 251, 1, 94, 1, 101, 79, 47, 13, 8, 208, 415, 7, 1, 34, 423, 23, 141, 1, 50, 20, 7, 338, 140, 128, 162, 381, 7, 401, 17, 18, 34, 423, 74, 1, 11, 140, 128, 38, 255, 1, 101, 1, 94, 47, 27, 7, 1, 373, 1, 373, 7, 1, 371, 169, 169, 215, 1, 7, 401, 17, 34, 423, 23, 141, 1, 50, 20, 7, 338, 7, 211, 128, 162, 381, 7, 401, 17, 18, 34, 423, 74, 1, 14, 9, 140, 128, 38, 175, 1, 101, 128, 1, 140, 38, 47, 13, 8, 7, 339, 336, 1, 58, 7, 404, 276, 171, 78, 152, 354, 317, 7, 401, 17, 34, 423, 20, 7, 280, 128, 162, 381, 48, 7, 401, 17, 293, 22, 34, 423, 74, 1, 14, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyUkoxCpcUBj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f52b69c3-d5c3-4a6e-c070-0a58f2a15722"
      },
      "source": [
        "# tokenize된 id 값을 string 으로 복원\n",
        "# id to sentence\n",
        "vocab.decode_ids(ids)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'위 ⁇ 백과의 최상위 도 ⁇ 인이 .co ⁇ 이던 시 ⁇  ko. ⁇ k ⁇ e ⁇ a.co ⁇ 에  ⁇   ⁇ 어위 ⁇ 가  ⁇ 으나 한 ⁇  처리에 문제가 있어  ⁇ 을  ⁇ 릴 수도  ⁇ 는 이 ⁇ 인  ⁇ 이 ⁇ 다. 2002 ⁇  10 ⁇ 에  ⁇ 로 ⁇  위 ⁇  소 ⁇ 어를  ⁇ 면서 한 ⁇  처리 문제가  ⁇ 리기 시작했지만, 가장 많은 사 ⁇ 이  ⁇ 는 인터 ⁇   ⁇ 스 ⁇ 로러에서는 인코 ⁇  문제가 여전했다. 이 ⁇  이유로  ⁇ 기에는 도 ⁇ 말을  ⁇ 기거나  ⁇ 는 일에 어려 ⁇ 을 겪 ⁇ 다. 이 ⁇  어려 ⁇ 이 있 ⁇ 는데도 위 ⁇ 백과 통계로는, 2002 ⁇  10 ⁇ 에서 2003 ⁇  7 ⁇ 까지 열 달 사이에  ⁇ 이 13개에서 159개로  ⁇ 고 2003 ⁇  7 ⁇ 과 8 ⁇  사이에는 한 달 만에 159개에서 348개로  ⁇ 어났다. 2003 ⁇  9 ⁇ 부터는 인터 ⁇   ⁇ 스 ⁇ 로러의 인코 ⁇  문제가 사라 ⁇ 으며, 대한민 ⁇   ⁇ 에서도  ⁇  차례 위 ⁇ 백과를 소개하면서 참여자가  ⁇ 증하리라고 예 ⁇ 했다. 참고로 한 ⁇ 어 위 ⁇ 백과의 최 ⁇  문서는 2002 ⁇  10 ⁇  12일에 등재된 지 ⁇  카터 문서이다. 2005 ⁇  6 ⁇  5일 양자장 ⁇  문서 등재를 기 ⁇ 으로 총 등재 문서 수가 1만 개를  ⁇ 파하 ⁇ 고 이어 동해 11 ⁇ 에 제1회 정보 ⁇ 러스 ⁇  어 ⁇ 드 인터 ⁇  문화 일반 분야에 선정되 ⁇ 다. 2007 ⁇  8 ⁇  9일에는 한 ⁇ 21에서 한 ⁇ 어 위 ⁇ 백과와 위 ⁇ 백과 오 ⁇ 라인  ⁇  모임을  ⁇ 재한 기사를 표지 이야기로 다 ⁇ 다. 2008 ⁇  광우 ⁇   ⁇  시위 때 생 ⁇  신조어인 명 ⁇ 산성이 한 ⁇ 어 위 ⁇ 백과에 등재되고 이 문서의 존치 여부를 두고  ⁇ 을 ⁇ 의 과정이 화제가 되고 각종  ⁇ 체에도 보도가 되 ⁇ 다. 시위대의 난 ⁇ 과 충 ⁇ 을 방지하기 위해 거리에 설치되 ⁇ 던  ⁇ 테이 ⁇   ⁇ 스를 이명 ⁇  정부의  ⁇ 통으로  ⁇ 자를 하기 위해 사용된 이 신조어는 중 ⁇ 성을 지 ⁇ 는지와 백과사전에  ⁇ 라 ⁇  만한 문서인지가  ⁇ 이 되 ⁇ 는데 일시적으로 사용된 신조어일  ⁇ 이라는 주장과 이 ⁇  여러  ⁇ 체에서 사용되어 지 ⁇ 성이 보장되 ⁇ 다는 주장 등 논 ⁇ 이  ⁇ 어 ⁇ 고 다음 아고라 등지에서 이  ⁇ 목을 존치하는 방안을 지지하는 의견을  ⁇ 기기 위해 여러 사 ⁇ 이  ⁇ 로 가 ⁇ 하는 등  ⁇ 이  ⁇ 어 ⁇ 다. 11 ⁇  4일에는 다음 ⁇ 니 ⁇ 이 ⁇ 에서  ⁇ 로 ⁇   ⁇ 계 대백과사전을 기증받았으며, 2009 ⁇  3 ⁇ 에는 서울특별시로부터  ⁇ 를 기증받았다. 2009 ⁇  6 ⁇  4일에는  ⁇ 스권 등재를 기 ⁇ 으로 10만 개 문서 수를  ⁇ 파했다. 2011 ⁇  4 ⁇  16일에는 대한민 ⁇ 에서의 위 ⁇ 어  ⁇ 로 ⁇ 를 지원하는 모임을 결성할 것을 추진하는 논의가 이 ⁇ 고 이후  ⁇ 준비위원회 결성을 거쳐 2014 ⁇  10 ⁇  19일  ⁇ 총회를 개최하 ⁇ 으며, 최종적으로 2015 ⁇  11 ⁇  4일 사단 ⁇ 인 한 ⁇  위 ⁇ 어 협회가 결성되어 활동 중에 있다. 2019 ⁇   ⁇  위 ⁇ 어재단으로부터 한 ⁇  지역 지부( ⁇ 터)로 승인을 받았다. 2012 ⁇  5 ⁇  19일에는 보비  ⁇  등재를 기 ⁇ 으로 총 20만 개 문서가 등재되 ⁇ 고 2015 ⁇  1 ⁇  5일,  ⁇ o ⁇ o  ⁇ erra ⁇  문서 등재를 기 ⁇ 으로 총 30만 개 문서가 등재되 ⁇ 다. 2017 ⁇  10 ⁇  21일에는 충청 ⁇ 도 동물위생시험소 문서 등재로 40만 개의 문서까지 등재되 ⁇ 다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaPhB9Cjcbmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "955d9a2f-4d84-4297-e320-c791324ee8e5"
      },
      "source": [
        "# id 값을 token으로 변경\n",
        "# id to piece\n",
        "id_pieces = []\n",
        "for id in ids:\n",
        "    id_pieces.append(vocab.id_to_piece(id))\n",
        "id_pieces[0:100]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁',\n",
              " '위',\n",
              " '[UNK]',\n",
              " '백',\n",
              " '과',\n",
              " '의',\n",
              " '▁최',\n",
              " '상',\n",
              " '위',\n",
              " '▁',\n",
              " '도',\n",
              " '[UNK]',\n",
              " '인',\n",
              " '이',\n",
              " '▁',\n",
              " '.',\n",
              " 'c',\n",
              " 'o',\n",
              " '[UNK]',\n",
              " '이',\n",
              " '던',\n",
              " '▁시',\n",
              " '[UNK]',\n",
              " '▁',\n",
              " 'k',\n",
              " 'o',\n",
              " '.',\n",
              " '[UNK]',\n",
              " 'k',\n",
              " '[UNK]',\n",
              " 'e',\n",
              " '[UNK]',\n",
              " 'a',\n",
              " '.',\n",
              " 'c',\n",
              " 'o',\n",
              " '[UNK]',\n",
              " '에',\n",
              " '▁',\n",
              " '[UNK]',\n",
              " '▁',\n",
              " '[UNK]',\n",
              " '어',\n",
              " '위',\n",
              " '[UNK]',\n",
              " '가',\n",
              " '▁',\n",
              " '[UNK]',\n",
              " '으',\n",
              " '나',\n",
              " '▁한',\n",
              " '[UNK]',\n",
              " '▁',\n",
              " '처',\n",
              " '리',\n",
              " '에',\n",
              " '▁',\n",
              " '문',\n",
              " '제',\n",
              " '가',\n",
              " '▁있',\n",
              " '어',\n",
              " '▁',\n",
              " '[UNK]',\n",
              " '을',\n",
              " '▁',\n",
              " '[UNK]',\n",
              " '릴',\n",
              " '▁수',\n",
              " '도',\n",
              " '▁',\n",
              " '[UNK]',\n",
              " '는',\n",
              " '▁이',\n",
              " '[UNK]',\n",
              " '인',\n",
              " '▁',\n",
              " '[UNK]',\n",
              " '이',\n",
              " '[UNK]',\n",
              " '다',\n",
              " '.',\n",
              " '▁2',\n",
              " '0',\n",
              " '0',\n",
              " '2',\n",
              " '[UNK]',\n",
              " '▁1',\n",
              " '0',\n",
              " '[UNK]',\n",
              " '에',\n",
              " '▁',\n",
              " '[UNK]',\n",
              " '로',\n",
              " '[UNK]',\n",
              " '▁',\n",
              " '위',\n",
              " '[UNK]',\n",
              " '▁',\n",
              " '소']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPe2xTM1FnoI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}